{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procurando datasets em: /home/supremo/Downloads/QuestionInsight-main/Extraidos\n",
      "‚úÖ Dataset encontrado: cb_dataset_2024_1_v1.81 -> /home/supremo/Downloads/QuestionInsight-main/Extraidos/cb_dataset_2024_1_v1.81/2024-1\n",
      "\n",
      "üìä Total de datasets encontrados: 1\n",
      "=== CODEBENCH ANALYTICS - EXECU√á√ÉO AUTOM√ÅTICA ===\n",
      "\n",
      "\n",
      "üîß Preparando ambiente...\n",
      "Executando Makefile em: /home/supremo/Downloads/QuestionInsight-main/Etapa_4/codebench-analytics-full\n",
      "Using virtualenv: /home/supremo/.cache/pypoetry/virtualenvs/codebench-analytics-GhrTdmgR-py3.11\n",
      "Installing dependencies from lock file\n",
      "\n",
      "No dependencies to install or update\n",
      "\n",
      "Installing the current project: codebench-analytics (0.1.0)\n",
      "\n",
      "üöÄ Executando an√°lise para os seguintes datasets:\n",
      " - /home/supremo/Downloads/QuestionInsight-main/Extraidos/cb_dataset_2024_1_v1.81/2024-1\n",
      "2025-06-10 10:35:43,951 codebench_analytics.extractor.execution_extractor INFO:extracting execution data from '/home/supremo/Downloads/QuestionInsight-main/Extraidos/cb_dataset_2024_1_v1.81/2024-1'\n",
      "2025-06-10 10:35:46,121 root INFO:generating 'executions_data.csv' file into 'output/data/executions_data.csv'\n",
      "2025-06-10 10:35:46,297 codebench_analytics.collector.executions INFO:collecting metrics from 'output/data/executions_data.csv'\n",
      "2025-06-10 10:35:46,469 root INFO:generating 'executions_by_student.csv' file into 'output/metrics/executions_by_student.csv'\n",
      "2025-06-10 10:35:46,482 root INFO:generating 'executions.csv' file into 'output/metrics/executions.csv'\n",
      "\n",
      "üìà Extraindo m√©tricas da solu√ß√£o: /home/supremo/Downloads/QuestionInsight-main/Etapa_4/codebench-analytics-full/codigo_solucao.csv\n",
      "2025-06-10 10:35:49,506 root INFO:generating 'code_metrics_professor.csv' file into 'output/data/code_metrics_professor.csv'\n",
      "\n",
      "‚úÖ Processamento conclu√≠do com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import re\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "dataset_paths = discover_datasets()\n",
    "\n",
    "# Caminho raiz do projeto (onde est√° o pyproject.toml)\n",
    "#PROJECT_DIR = Path(\"/home/supremo/Downloads/QuestionInsight-main/Etapa_4/codebench-analytics-full\").resolve()\n",
    "\n",
    "# Diret√≥rio onde est√£o os datasets extra√≠dos\n",
    "#EXTRAIDOS_DIR = Path(\"/home/supremo/Downloads/QuestionInsight-main/Extraidos\").resolve()\n",
    "\n",
    "# Caminho raiz do projeto (onde est√° o pyproject.toml)\n",
    "PROJECT_DIR = Path(\"./codebench-analytics-full\").resolve()\n",
    "\n",
    "# O diret√≥rio de extra√≠dos est√° um n√≠vel acima do local atual.\n",
    "EXTRAIDOS_DIR = Path(\"../Extraidos\").resolve()\n",
    "\n",
    "def extract_year_semester_from_folder(folder_name):\n",
    "    \"\"\"\n",
    "    Extrai ano e semestre do nome da pasta.\n",
    "    Exemplo: cb_dataset_2018_1_v1.81 -> (2018, 1)\n",
    "    \"\"\"\n",
    "    match = re.search(r'cb_dataset_(\\d{4})_(\\d+)_v', folder_name)\n",
    "    if match:\n",
    "        year = match.group(1)\n",
    "        semester = match.group(2)\n",
    "        return year, semester\n",
    "    return None, None\n",
    "\n",
    "def discover_datasets():\n",
    "    \"\"\"\n",
    "    Descobre automaticamente os datasets na pasta Extraidos\n",
    "    e constr√≥i os caminhos seguindo o padr√£o atual.\n",
    "    \"\"\"\n",
    "    print(f\"Procurando datasets em: {EXTRAIDOS_DIR}\")\n",
    "    \n",
    "    if not EXTRAIDOS_DIR.exists():\n",
    "        print(f\"‚ùå Diret√≥rio Extraidos n√£o encontrado: {EXTRAIDOS_DIR}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    dataset_paths = []\n",
    "    \n",
    "    # Procurar por pastas que seguem o padr√£o cb_dataset_*\n",
    "    for item in EXTRAIDOS_DIR.iterdir():\n",
    "        if item.is_dir() and item.name.startswith(\"cb_dataset_\"):\n",
    "            year, semester = extract_year_semester_from_folder(item.name)\n",
    "            \n",
    "            if year and semester:\n",
    "                # Construir o caminho seguindo o padr√£o: pasta_dataset/ano-semestre\n",
    "                dataset_path = item / f\"{year}-{semester}\"\n",
    "                \n",
    "                if dataset_path.exists():\n",
    "                    dataset_paths.append(str(dataset_path.resolve()))\n",
    "                    print(f\"‚úÖ Dataset encontrado: {item.name} -> {dataset_path}\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è  Pasta interna n√£o encontrada: {dataset_path}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  N√£o foi poss√≠vel extrair ano/semestre de: {item.name}\")\n",
    "    \n",
    "    if not dataset_paths:\n",
    "        print(\"‚ùå Nenhum dataset v√°lido encontrado!\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Ordenar os caminhos para processamento consistente\n",
    "    dataset_paths.sort()\n",
    "    \n",
    "    print(f\"\\nüìä Total de datasets encontrados: {len(dataset_paths)}\")\n",
    "    return dataset_paths\n",
    "\n",
    "def run_makefile():\n",
    "    print(f\"Executando Makefile em: {PROJECT_DIR}\")\n",
    "    result = subprocess.run([\"make\"], cwd=PROJECT_DIR)\n",
    "    if result.returncode != 0:\n",
    "        print(\"‚ùå Erro ao executar o Makefile.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def run_execution_command(*paths):\n",
    "    print(\"\\nüöÄ Executando an√°lise para os seguintes datasets:\")\n",
    "    for p in paths:\n",
    "        print(f\" - {p}\")\n",
    "\n",
    "    # Cria uma lista com um '-p' antes de cada caminho\n",
    "    p_args = []\n",
    "    for p in paths:\n",
    "        p_args.extend([\"-p\", p])\n",
    "\n",
    "    command = [\"poetry\", \"run\", \"codebench_analytics\", \"execution\", *p_args, \"-k\", \"exam\"]\n",
    "    result = subprocess.run(command, cwd=PROJECT_DIR)\n",
    "    if result.returncode != 0:\n",
    "        print(\"‚ùå Erro ao executar o comando de execu√ß√£o.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def run_solution_command(solution_path):\n",
    "    print(f\"\\nüìà Extraindo m√©tricas da solu√ß√£o: {solution_path}\")\n",
    "    command = [\"poetry\", \"run\", \"codebench_analytics\", \"solution\", \"-p\", solution_path]\n",
    "    result = subprocess.run(command, cwd=PROJECT_DIR)\n",
    "    if result.returncode != 0:\n",
    "        print(\"‚ùå Erro ao extrair m√©tricas da solu√ß√£o.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def main():\n",
    "    print(\"=== CODEBENCH ANALYTICS - EXECU√á√ÉO AUTOM√ÅTICA ===\\n\")\n",
    "    \n",
    "    # Descobrir datasets automaticamente\n",
    "    \n",
    "    \n",
    "    # Executar Makefile\n",
    "    print(f\"\\nüîß Preparando ambiente...\")\n",
    "    run_makefile()\n",
    "\n",
    "    # Executar an√°lise de execu√ß√£o\n",
    "    run_execution_command(*dataset_paths)\n",
    "\n",
    "    # Caminho para o CSV da solu√ß√£o\n",
    "    solution_csv = PROJECT_DIR / \"codigo_solucao.csv\"\n",
    "    if not solution_csv.exists():\n",
    "        print(f\"‚ùå Arquivo de solu√ß√£o n√£o encontrado: {solution_csv}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    run_solution_command(str(solution_csv))\n",
    "    \n",
    "    print(\"\\n‚úÖ Processamento conclu√≠do com sucesso!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando Makefile em: /home/supremo/Downloads/QuestionInsight-main/Etapa_4/codebench-analytics-full\n",
      "Using virtualenv: /home/supremo/.cache/pypoetry/virtualenvs/codebench-analytics-GhrTdmgR-py3.11\n",
      "Installing dependencies from lock file\n",
      "\n",
      "No dependencies to install or update\n",
      "\n",
      "Installing the current project: codebench-analytics (0.1.0)\n",
      "Executando an√°lise de execu√ß√£o para os seguintes datasets:\n",
      " - /home/supremo/Downloads/QuestionInsight-main/Extraidos/cb_dataset_2024_1_v1.81/2024-1\n",
      "2025-06-10 10:36:00,738 codebench_analytics.extractor.execution_extractor INFO:extracting execution data from '/home/supremo/Downloads/QuestionInsight-main/Extraidos/cb_dataset_2024_1_v1.81/2024-1'\n",
      "2025-06-10 10:36:02,810 root INFO:generating 'executions_data.csv' file into 'output/data/executions_data.csv'\n",
      "2025-06-10 10:36:02,982 codebench_analytics.collector.executions INFO:collecting metrics from 'output/data/executions_data.csv'\n",
      "2025-06-10 10:36:03,149 root INFO:generating 'executions_by_student.csv' file into 'output/metrics/executions_by_student.csv'\n",
      "2025-06-10 10:36:03,161 root INFO:generating 'executions.csv' file into 'output/metrics/executions.csv'\n",
      "Executando an√°lise de a√ß√µes para os seguintes datasets:\n",
      " - /home/supremo/Downloads/QuestionInsight-main/Extraidos/cb_dataset_2024_1_v1.81/2024-1\n",
      "2025-06-10 10:36:03,720 codebench_analytics.extractor.action_extractor INFO:extracting 'codemirror' from '/home/supremo/Downloads/QuestionInsight-main/Extraidos/cb_dataset_2024_1_v1.81/2024-1'\n",
      "2025-06-10 10:37:19,283 codebench_analytics.extractor.action_extractor WARNING:Invalid JSON format in metadata: {\"from\":{\"line\":4,\"ch\":9,\"sticky\":null},\"to\":{\"line\":4,\n",
      "2025-06-10 10:39:08,659 codebench_analytics.extractor.action_extractor WARNING:Invalid JSON format in metadata: {\"from\":{\"line\":5,\"ch10/6/2024@16:24:18:810#tab-click:6780#\n",
      "2025-06-10 10:39:11,980 codebench_analytics.extractor.action_extractor WARNING:Invalid JSON format in metadata: {\"key\":%10/6/2024@16:26:26:425#tab-click:6765#\n",
      "2025-06-10 10:39:22,123 codebench_analytics.extractor.action_extractor WARNING:Invalid JSON format in metadata: {\"from\":{\"line\":8,\"ch\":12,\"sticky\":null},\"to\":{\"line\":8,\"ch\":12,\"sticky\":null},\"text\":[10/6/2024@16:26:53:901#tab-click:6760#\n",
      "2025-06-10 10:39:32,624 codebench_analytics.extractor.action_extractor WARNING:Invalid JSON format in metadata: tab-click:6784#\n",
      "2025-06-10 10:39:35,056 root INFO:generating 'actions.csv' file into 'output/data/actions.csv'\n",
      "2025-06-10 10:40:00,837 codebench_analytics.collector.actions INFO:collecting student actions from 'output/data/actions.csv'\n",
      "2025-06-10 10:41:24,950 root INFO:generating 'actions_by_student.csv' file into 'output/metrics/actions_by_student.csv'\n",
      "2025-06-10 10:41:25,052 root INFO:generating 'actions_data.csv' file into 'output/metrics/actions_data.csv'\n",
      "Extraindo m√©tricas da solu√ß√£o: /home/supremo/Downloads/QuestionInsight-main/Etapa_4/codebench-analytics-full/codigo_solucao.csv\n",
      "2025-06-10 10:41:38,251 root INFO:generating 'code_metrics_professor.csv' file into 'output/data/code_metrics_professor.csv'\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Caminho raiz do projeto (onde est√° o pyproject.toml)\n",
    "#PROJECT_DIR = Path(\"/home/supremo/Downloads/Trabalho_CodeBench_WEI/Etapa_4/codebench-analytics-full\").resolve()\n",
    "\n",
    "def run_makefile():\n",
    "    print(f\"Executando Makefile em: {PROJECT_DIR}\")\n",
    "    result = subprocess.run([\"make\"], cwd=PROJECT_DIR)\n",
    "    if result.returncode != 0:\n",
    "        print(\"‚ùå Erro ao executar o Makefile.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def run_execution_command(*paths):\n",
    "    print(\"Executando an√°lise de execu√ß√£o para os seguintes datasets:\")\n",
    "    for p in paths:\n",
    "        print(f\" - {p}\")\n",
    "    \n",
    "    # Cria uma lista com um '-p' antes de cada caminho\n",
    "    p_args = []\n",
    "    for p in paths:\n",
    "        p_args.extend([\"-p\", p])\n",
    "    \n",
    "    command = [\"poetry\", \"run\", \"codebench_analytics\", \"execution\", *p_args, \"-k\", \"exam\"]\n",
    "    result = subprocess.run(command, cwd=PROJECT_DIR)\n",
    "    if result.returncode != 0:\n",
    "        print(\"‚ùå Erro ao executar o comando de execu√ß√£o.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def run_action_command(*paths):\n",
    "    print(\"Executando an√°lise de a√ß√µes para os seguintes datasets:\")\n",
    "    for p in paths:\n",
    "        print(f\" - {p}\")\n",
    "    \n",
    "    # Cria uma lista com um '-p' antes de cada caminho\n",
    "    p_args = []\n",
    "    for p in paths:\n",
    "        p_args.extend([\"-p\", p])\n",
    "    \n",
    "    command = [\"poetry\", \"run\", \"codebench_analytics\", \"action\", *p_args, \"-k\", \"exam\"]\n",
    "    result = subprocess.run(command, cwd=PROJECT_DIR)\n",
    "    if result.returncode != 0:\n",
    "        print(\"‚ùå Erro ao executar o comando de a√ß√£o.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def run_solution_command(solution_path):\n",
    "    print(f\"Extraindo m√©tricas da solu√ß√£o: {solution_path}\")\n",
    "    command = [\"poetry\", \"run\", \"codebench_analytics\", \"solution\", \"-p\", solution_path]\n",
    "    result = subprocess.run(command, cwd=PROJECT_DIR)\n",
    "    if result.returncode != 0:\n",
    "        print(\"‚ùå Erro ao extrair m√©tricas da solu√ß√£o.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def main():\n",
    "    run_makefile()\n",
    "    \n",
    "    # Lista dos datasets ‚Äî altere conforme necess√°rio\n",
    "    \"\"\"dataset_paths = [\n",
    "        \"/home/supremo/Downloads/Trabalho_CodeBench_WEI/Extraidos/cb_dataset_2018_1_v1.81/2018-1\",\n",
    "        \"/home/supremo/Downloads/Trabalho_CodeBench_WEI/Extraidos/cb_dataset_2018_2_v1.81/2018-2\",\n",
    "    ]\n",
    "    \n",
    "    # Resolve para caminhos absolutos\n",
    "    dataset_paths = [str(Path(p).resolve()) for p in dataset_paths]\n",
    "    \"\"\"\n",
    "    # Executa tanto execution quanto action\n",
    "    run_execution_command(*dataset_paths)\n",
    "    run_action_command(*dataset_paths)\n",
    "    \n",
    "    # Caminho para o CSV da solu√ß√£o\n",
    "    solution_csv = PROJECT_DIR / \"codigo_solucao.csv\"\n",
    "    if not solution_csv.exists():\n",
    "        print(f\"‚ùå Arquivo de solu√ß√£o n√£o encontrado: {solution_csv}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    run_solution_command(str(solution_csv))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explica√ß√£o do C√≥digo\n",
    "\n",
    "## O que o c√≥digo faz:\n",
    "1. **Carregamento de Arquivos CSV**:\n",
    "   - Carrega dois arquivos CSV usando `pandas`:\n",
    "     - `actions_data.csv`: cont√©m informa√ß√µes sobre tempos e eventos relacionados a a√ß√µes.\n",
    "     - `executions.csv`: cont√©m informa√ß√µes sobre intera√ß√µes e resultados relacionados √†s execu√ß√µes.\n",
    "\n",
    "2. **Renomea√ß√£o de Colunas**:\n",
    "   - Renomeia algumas colunas dos dois arquivos para facilitar a combina√ß√£o e tornar os nomes mais descritivos:\n",
    "     - No `actions_data.csv`:\n",
    "       - `code_time` ‚Üí `tempo_implementacao`\n",
    "       - `num_events` ‚Üí `num_eventos`\n",
    "       - `num_deletes` ‚Üí `num_eventos_del`\n",
    "     - No `executions.csv`:\n",
    "       - `num_submissions` ‚Üí `num_submissoes`\n",
    "       - `num_students_interactions` ‚Üí `num_consultas`\n",
    "       - `amount_of_change` ‚Üí `qtd_alteracoes_codigo`\n",
    "\n",
    "3. **Uni√£o dos Dados**:\n",
    "   - Combina os dois DataFrames com base na coluna `question`, utilizando um merge √† esquerda (`how='left'`), o que preserva todas as linhas de `executions.csv`.\n",
    "\n",
    "4. **Sele√ß√£o de Colunas**:\n",
    "   - Cria um novo DataFrame contendo apenas as colunas relevantes para a an√°lise:\n",
    "     - `question`, `tempo_implementacao`, `num_eventos`, `num_eventos_del`, `num_consultas`, `num_submissoes`, `num_tests`, `num_correct`, `num_errors`, `num_logic_errors`, `num_syntax_errors`, `qtd_alteracoes_codigo`.\n",
    "\n",
    "5. **Exporta√ß√£o para CSV**:\n",
    "   - Salva o DataFrame resultante em um novo arquivo chamado `resultado.csv`.\n",
    "\n",
    "6. **Mensagem de Sucesso**:\n",
    "   - Exibe uma mensagem no console indicando que o arquivo foi gerado com sucesso.\n",
    "\n",
    "## Resultado:\n",
    "- Um arquivo CSV chamado `resultado.csv`, contendo as colunas combinadas e selecionadas dos dois arquivos originais, est√° pronto para ser usado em an√°lises ou relat√≥rios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'resultado.csv' gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar os dois arquivos CSV\n",
    "df1 = pd.read_csv(r'codebench-analytics-full/output/metrics/actions_data.csv')  # Primeiro arquivo com os tempos e eventos\n",
    "df2 = pd.read_csv(r'codebench-analytics-full/output/metrics/executions.csv')  # Segundo arquivo com as intera√ß√µes e resultados\n",
    "\n",
    "# Renomear colunas para facilitar a combina√ß√£o\n",
    "df1.rename(columns={\n",
    "    'code_time': 'tempo_implementacao',\n",
    "    'num_events': 'num_eventos',\n",
    "    'num_deletes': 'num_eventos_del'\n",
    "}, inplace=True)\n",
    "\n",
    "# Renomear colunas do segundo DataFrame\n",
    "df2.rename(columns={\n",
    "    'num_submissions': 'num_submissoes',\n",
    "    'num_students_interactions': 'num_consultas',  # Renomeando para compatibilidade\n",
    "    'amount_of_change': 'qtd_alteracoes_codigo'  # Renomeando para compatibilidade\n",
    "}, inplace=True)\n",
    "\n",
    "# Unir os DataFrames com base na coluna 'question'\n",
    "merged_df = pd.merge(df2, df1, on='question', how='left')\n",
    "\n",
    "# Selecionar apenas as colunas desejadas para o novo DataFrame\n",
    "final_df = merged_df[['question', 'tempo_implementacao', 'num_eventos', 'num_eventos_del', \n",
    "                       'num_consultas', 'num_submissoes',  # Usando 'num_consultas' renomeado\n",
    "                       'num_tests', 'num_correct', 'num_errors', \n",
    "                       'num_logic_errors', 'num_syntax_errors', 'qtd_alteracoes_codigo']]  # Usando 'qtd_alteracoes_codigo' renomeado\n",
    "\n",
    "# Salvar o DataFrame resultante em um novo arquivo CSV\n",
    "final_df.to_csv('resultado.csv', index=False)\n",
    "\n",
    "print(\"Arquivo 'resultado.csv' gerado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explica√ß√£o do C√≥digo\n",
    "\n",
    "Este c√≥digo tem como objetivo ler um arquivo CSV, manipular os dados e salvar um novo arquivo com os resultados. O processo √© o seguinte:\n",
    "\n",
    "1. **Leitura do arquivo CSV**: \n",
    "   O arquivo `'unified_solutions.csv'` √© carregado em um DataFrame utilizando a biblioteca `pandas`.\n",
    "\n",
    "2. **Cria√ß√£o de nova coluna**:\n",
    "   Uma nova coluna chamada `'id'` √© criada, copiando os valores da coluna `'assignment'`.\n",
    "\n",
    "3. **Remo√ß√£o de duplicatas**:\n",
    "   A coluna `'id'` √© filtrada para remover duplicatas, criando um novo DataFrame com valores √∫nicos.\n",
    "\n",
    "4. **Salvamento dos dados**:\n",
    "   O novo DataFrame √© salvo em um arquivo CSV chamado `'assessments.csv'`.\n",
    "\n",
    "5. **Mensagem de sucesso**:\n",
    "   Uma mensagem √© exibida para informar que o arquivo de sa√≠da foi criado com sucesso.\n",
    "\n",
    "### C√≥digo\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "input_file = 'unified_solutions.csv'\n",
    "output_file = 'assessments.csv'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "df['id'] = df['assignment']\n",
    "df_output = df[['id']].drop_duplicates()\n",
    "\n",
    "df_output.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Arquivo '{output_file}' criado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'assessments.csv' criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo de entrada e nome do arquivo de sa√≠da\n",
    "input_file = '../CSVS_JO/unified_solutions.csv'  # Substitua pelo nome do seu arquivo CSV\n",
    "output_file = 'assessments.csv'\n",
    "\n",
    "# Carrega o CSV de entrada\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Cria a coluna 'id' a partir da coluna 'assignment'\n",
    "df['id'] = df['assignment']\n",
    "\n",
    "# Remove duplicatas da coluna 'id'\n",
    "df_output = df[['id']].drop_duplicates()\n",
    "\n",
    "# Salva o novo DataFrame em um arquivo CSV\n",
    "df_output.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Arquivo '{output_file}' criado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explica√ß√£o do C√≥digo\n",
    "\n",
    "## O que o c√≥digo faz:\n",
    "\n",
    "1. **Importa√ß√£o do M√≥dulo CSV**:\n",
    "   - Utiliza o m√≥dulo `csv` do Python para manipular arquivos CSV.\n",
    "\n",
    "2. **Fun√ß√£o para Leitura de CSV**:\n",
    "   - A fun√ß√£o `ler_csv`:\n",
    "     - Recebe o nome de um arquivo CSV.\n",
    "     - L√™ o conte√∫do do arquivo e retorna uma lista de dicion√°rios, onde cada linha do CSV √© representada como um dicion√°rio.\n",
    "\n",
    "3. **Leitura dos Arquivos de Entrada**:\n",
    "   - `dados_question`: Cont√©m informa√ß√µes sobre as quest√µes (ex.: tempo de implementa√ß√£o, n√∫mero de eventos, etc.), lido de `resultado.csv`.\n",
    "   - `dados_respostas`: Cont√©m informa√ß√µes adicionais sobre as quest√µes (ex.: dificuldade, discrimina√ß√£o, etc.), lido de `questoes_ordenadas.csv`.\n",
    "\n",
    "4. **Combina√ß√£o dos Dados**:\n",
    "   - Para cada quest√£o em `dados_question`:\n",
    "     - Procura a quest√£o correspondente em `dados_respostas` (compara a coluna `id` com `question`).\n",
    "     - Cria um novo registro com informa√ß√µes combinadas de ambos os arquivos.\n",
    "\n",
    "5. **Estrutura do Novo Registro**:\n",
    "   - As informa√ß√µes do novo registro incluem:\n",
    "     - Dados da quest√£o (`tempo_implementacao`, `num_eventos`, `num_tests`, etc.).\n",
    "     - Dados adicionais das respostas (`dificuldade`, `discriminacao`, etc.).\n",
    "\n",
    "6. **Escrita do Arquivo Resultante**:\n",
    "   - Salva os registros combinados em um novo arquivo chamado `question_new_info.csv`:\n",
    "     - Escreve um cabe√ßalho com os nomes das colunas.\n",
    "     - Adiciona as linhas dos registros combinados.\n",
    "\n",
    "7. **Mensagem de Sucesso**:\n",
    "   - Exibe uma mensagem no console indicando que os dados foram combinados e salvos com sucesso.\n",
    "\n",
    "## Resultado:\n",
    "- Um arquivo CSV chamado `question_new_info.csv` √© gerado, contendo informa√ß√µes combinadas de `resultado.csv` e `questoes_ordenadas.csv`.\n",
    "- Esse arquivo pode ser usado para an√°lises completas das quest√µes e suas respectivas m√©tricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados combinados e salvos em question_new_info.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Fun√ß√£o para ler um CSV e retornar como uma lista de dicion√°rios\n",
    "def ler_csv(nome_arquivo):\n",
    "    with open(nome_arquivo, mode='r', newline='') as arquivo_csv:\n",
    "        leitor = csv.DictReader(arquivo_csv)\n",
    "        return [linha for linha in leitor]\n",
    "\n",
    "# Lendo os arquivos CSV de entrada\n",
    "dados_question = ler_csv(r'resultado.csv')\n",
    "dados_respostas = ler_csv(r'../Etapa_3/questoes_ordenadas.csv')\n",
    "\n",
    "# Criar um novo registro para cada linha de dados_question\n",
    "resultados = []\n",
    "\n",
    "for question in dados_question:\n",
    "    # Encontrar a resposta correspondente\n",
    "    for resposta in dados_respostas:\n",
    "        if int(resposta['id']) == int(question['question']):\n",
    "            novo_registro = {\n",
    "                \"question\": question['question'],\n",
    "                \"tempo_implementacao\": question['tempo_implementacao'],\n",
    "                \"num_eventos\": question['num_eventos'],\n",
    "                \"num_eventos_del\": question['num_eventos_del'],\n",
    "                \"num_consultas\": question['num_consultas'],\n",
    "                \"num_submissoes\": question['num_submissoes'],\n",
    "                \"num_tests\": question['num_tests'],\n",
    "                \"num_correct\": question['num_correct'],\n",
    "                \"num_errors\": question['num_errors'],\n",
    "                \"num_logic_errors\": question['num_logic_errors'],\n",
    "                \"num_syntax_errors\": question['num_syntax_errors'],\n",
    "                \"qtd_alteracoes_codigo\": question['qtd_alteracoes_codigo'],\n",
    "                \"dificuldade\": resposta['dificuldade'],\n",
    "                \"discriminacao\": resposta['discriminacao'],\n",
    "                \"respostas\": resposta['respostas'],\n",
    "                \"usuarios_respondidos\": resposta['usuarios_respondidos']\n",
    "            }\n",
    "            resultados.append(novo_registro)\n",
    "\n",
    "# Escrever os resultados em um novo arquivo CSV\n",
    "with open('question_new_info.csv', mode='w', newline='') as arquivo_csv:\n",
    "    campos = resultados[0].keys()\n",
    "    escritor_csv = csv.DictWriter(arquivo_csv, fieldnames=campos)\n",
    "\n",
    "    escritor_csv.writeheader()\n",
    "    escritor_csv.writerows(resultados)\n",
    "\n",
    "print(\"Dados combinados e salvos em question_new_info.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'question_new_info.csv' foi ordenado e salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def ordenar_question(arquivo_question):\n",
    "    # Ler o arquivo CSV\n",
    "    question_df = pd.read_csv(arquivo_question)\n",
    "\n",
    "    # Ordenar o DataFrame pela coluna 'question'\n",
    "    question_df_sorted = question_df.sort_values(by='question', ascending=True)\n",
    "\n",
    "    # Sobrescrever o arquivo original com o DataFrame ordenado\n",
    "    question_df_sorted.to_csv(arquivo_question, index=False)\n",
    "\n",
    "    print(f\"Arquivo '{arquivo_question}' foi ordenado e salvo com sucesso.\")\n",
    "\n",
    "# Exemplo de uso\n",
    "arquivo_question = 'question_new_info.csv'\n",
    "ordenar_question(arquivo_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo gerado: code_metrics_professor_util.csv\n",
      "Nome da coluna alterado com sucesso no arquivo 'code_metrics_professor_util.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def comparar_e_gerar_csv(arquivo_question, arquivo_metrics, arquivo_saida):\n",
    "    # Ler os arquivos CSV\n",
    "    question_df = pd.read_csv(arquivo_question)\n",
    "    metrics_df = pd.read_csv(arquivo_metrics)\n",
    "\n",
    "    # Renomear a coluna 'question' para 'question_id' em question_df para facilitar a jun√ß√£o\n",
    "    question_df.rename(columns={'question': 'question_id'}, inplace=True)\n",
    "\n",
    "    # Fazer a jun√ß√£o dos DataFrames com base na coluna 'question_id'\n",
    "    merged_df = pd.merge(metrics_df, question_df, on='question_id', how='inner')\n",
    "\n",
    "    # Ordenar o DataFrame resultante com base na ordem de 'question_id' do question_df original\n",
    "    merged_df = merged_df.sort_values(by='question_id')\n",
    "\n",
    "    # Selecionar as colunas que voc√™ deseja manter\n",
    "    colunas_a_manter = metrics_df.columns.tolist()  # Manter todas as colunas do metrics_df\n",
    "\n",
    "    # Salvar o DataFrame resultante em um novo arquivo CSV\n",
    "    merged_df.to_csv(arquivo_saida, columns=colunas_a_manter, index=False)\n",
    "\n",
    "# Exemplo de uso com uma string \"raw\"\n",
    "comparar_e_gerar_csv(\n",
    "    'question_new_info.csv', \n",
    "    r'codebench-analytics-full/output/data/code_metrics_professor.csv', #Etapa_4/codebench-analytics-full/output\n",
    "    'code_metrics_professor_util.csv'\n",
    ")\n",
    "\n",
    "print(\"Arquivo gerado: code_metrics_professor_util.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Ler o arquivo CSV\n",
    "df = pd.read_csv('code_metrics_professor_util.csv')\n",
    "\n",
    "# Renomear a coluna 'question_id' para 'question'\n",
    "df.rename(columns={'question_id': 'question'}, inplace=True)\n",
    "\n",
    "# Salvar o DataFrame com o novo nome da coluna\n",
    "df.to_csv('code_metrics_professor_util.csv', index=False)\n",
    "\n",
    "print(\"Nome da coluna alterado com sucesso no arquivo 'code_metrics_professor_util.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
